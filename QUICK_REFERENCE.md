# ğŸš€ Quick Reference Card

## ğŸ“ Project Structure at a Glance

```
ukraine-tweets-sentiment-analysis/
â”‚
â”œâ”€â”€ ğŸ“– README.md                           â† Start here!
â”œâ”€â”€ ğŸ”§ docker-compose.yml                  â† Services config
â”œâ”€â”€ âš™ï¸ .env                                â† Environment vars
â”‚
â”œâ”€â”€ ğŸ“š docs/                               â† All documentation
â”‚   â”œâ”€â”€ QUICKSTART.md                      â† Step-by-step tutorial
â”‚   â”œâ”€â”€ SUPERSET_CONNECTION_GUIDE.md      â† â­ Visualization setup
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md                â† Common issues
â”‚   â”œâ”€â”€ ARCHITECTURE.md                    â† System design
â”‚   â””â”€â”€ INDEX.md                           â† Doc navigation
â”‚
â”œâ”€â”€ ğŸ› ï¸ tools/                              â† Utility scripts
â”‚   â”œâ”€â”€ data_preparation/                  â† Data sampling
â”‚   â”‚   â”œâ”€â”€ create_sample_100.py          â† Quick test (100 rows)
â”‚   â”‚   â””â”€â”€ download_dataset.py           â† Full dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ database_loaders/                  â† Load to DB
â”‚   â”‚   â””â”€â”€ load_to_postgres_sqlalchemy.py â† â­ Use this!
â”‚   â”‚
â”‚   â””â”€â”€ diagnostics/                       â† Monitoring
â”‚       â”œâ”€â”€ verify_postgres.py            â† Check data
â”‚       â””â”€â”€ view_results.py               â† View results
â”‚
â”œâ”€â”€ âš™ï¸ config/                             â† Configuration
â”œâ”€â”€ ğŸ”„ airflow/                            â† Airflow DAGs
â”œâ”€â”€ âš¡ spark/                              â† Spark jobs
â”œâ”€â”€ ğŸ“Š superset/                           â† Superset config
â”œâ”€â”€ ğŸ“‚ data/                               â† Data storage
â””â”€â”€ ğŸ”§ scripts/                            â† Setup scripts
```

## âš¡ Common Commands

### Quick Start (100-row test)

```bash
# 1. Create test sample
python tools/data_preparation/create_sample_100.py

# 2. Start services
docker-compose up -d

# 3. Run pipeline (Airflow UI: http://localhost:8080)
# Enable and trigger: twitter_sentiment_pipeline

# 4. Load results
python tools/database_loaders/load_to_postgres_sqlalchemy.py

# 5. Verify
python tools/diagnostics/verify_postgres.py

# 6. Visualize (Superset: http://localhost:8088)
# Follow: docs/SUPERSET_CONNECTION_GUIDE.md
```

### Docker Operations

```bash
# Start all services
docker-compose up -d

# Stop all services
docker-compose down

# View logs
docker-compose logs -f [service]

# Restart service
docker-compose restart [service]

# Check status
docker-compose ps
```

### Data Operations

```bash
# Create 100-row sample (testing)
python tools/data_preparation/create_sample_100.py

# Create custom sample
python tools/data_preparation/create_sample_dataset.py

# Download full dataset
python tools/data_preparation/download_dataset.py
```

### Database Operations

```bash
# Load to PostgreSQL (recommended)
python tools/database_loaders/load_to_postgres_sqlalchemy.py

# Verify data
python tools/diagnostics/verify_postgres.py

# View results
python tools/diagnostics/view_results.py
```

### Monitoring

```bash
# Monitor pipeline
python tools/diagnostics/monitor_pipeline.py

# Check Druid
python tools/diagnostics/check_druid_data.py
```

## ğŸŒ Service URLs

| Service      | URL                   | Login             |
| ------------ | --------------------- | ----------------- |
| **Airflow**  | http://localhost:8080 | airflow / airflow |
| **Spark**    | http://localhost:8081 | -                 |
| **Druid**    | http://localhost:8888 | -                 |
| **Superset** | http://localhost:8088 | admin / admin     |

## ğŸ¯ Workflow Paths

### New User Path

```
README.md
  â†“
docs/QUICKSTART.md
  â†“
tools/data_preparation/create_sample_100.py
  â†“
Airflow UI (run pipeline)
  â†“
tools/database_loaders/load_to_postgres_sqlalchemy.py
  â†“
docs/SUPERSET_CONNECTION_GUIDE.md
  â†“
Superset (create dashboards)
```

### Troubleshooting Path

```
Issue occurs
  â†“
docs/TROUBLESHOOTING.md
  â†“
docker-compose logs -f [service]
  â†“
tools/diagnostics/ (verify data)
  â†“
Solution found
```

### Scaling to Production

```
Test with 100 rows (works)
  â†“
tools/data_preparation/download_dataset.py
  â†“
Update DAG (use full dataset)
  â†“
Increase Docker resources
  â†“
Run full pipeline
  â†“
Load to PostgreSQL
  â†“
Production dashboards
```

## ğŸ“š Documentation Quick Links

| Need                        | Document                            |
| --------------------------- | ----------------------------------- |
| **Getting started**         | `README.md`                         |
| **Step-by-step tutorial**   | `docs/QUICKSTART.md`                |
| **Visualize data**          | `docs/SUPERSET_CONNECTION_GUIDE.md` |
| **Fix issues**              | `docs/TROUBLESHOOTING.md`           |
| **Understand architecture** | `docs/ARCHITECTURE.md`              |
| **Tool reference**          | `tools/README.md`                   |
| **Migration help**          | `MIGRATION_GUIDE.md`                |
| **Browse all docs**         | `docs/INDEX.md`                     |

## ğŸ”‘ Key Files

| File                                     | Purpose               |
| ---------------------------------------- | --------------------- |
| `docker-compose.yml`                     | Service definitions   |
| `.env`                                   | Environment variables |
| `airflow/dags/twitter_sentiment_dag.py`  | Pipeline definition   |
| `spark/sentiment_analysis.py`            | Analysis job          |
| `data/raw/ukraine_tweets_sample_100.csv` | Test data             |
| `data/processed/sentiment_results/*.csv` | Results               |

## ğŸš¨ Emergency Commands

### Services won't start

```bash
docker-compose down -v    # Nuclear option (âš ï¸ deletes data!)
docker-compose up -d      # Fresh start
```

### Pipeline fails

```bash
# Check Airflow logs
docker-compose logs -f airflow-scheduler

# Check specific task in Airflow UI
# http://localhost:8080 â†’ DAG â†’ Task â†’ Log
```

### Can't connect to database

```bash
# Restart PostgreSQL
docker-compose restart postgres

# Verify it's running
docker-compose ps | grep postgres
```

### Out of memory

```bash
# Increase Docker memory (Docker Desktop â†’ Settings â†’ Resources)
# Minimum: 8GB RAM, 4 CPUs
```

## ğŸ’¡ Pro Tips

1. **Start small**: Use 100-row sample first
2. **Check logs**: `docker-compose logs -f [service]`
3. **Use recommended tools**: Look for â­ markers
4. **Follow guides**: Docs are comprehensive
5. **Monitor progress**: Use Airflow UI
6. **Verify each step**: Use diagnostic tools

## ğŸ“ Learning Path

```
Day 1: Setup & 100-row test
  - Read README.md
  - Follow QUICKSTART.md
  - Run pipeline with sample

Day 2: Visualization
  - Load to PostgreSQL
  - Connect Superset
  - Create first chart

Day 3: Scale up
  - Larger sample (1K-10K rows)
  - Optimize performance
  - Create dashboard

Day 4+: Production
  - Full dataset
  - Advanced visualizations
  - Monitoring setup
```

---

**Quick Help**: Check `docs/TROUBLESHOOTING.md` or `docs/INDEX.md`
